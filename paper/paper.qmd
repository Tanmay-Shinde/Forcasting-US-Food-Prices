---
title: "Understanding Regional and Temporal Variations in Food Prices: Insights from US Consumer Price Index and Economic Trends"
subtitle: "--- TODO: CHANGE --- A Bayesian Approach Reveals the Impact of Economic Indicators and Geographic Disparities on Price Dynamics"
author: 
  - Tanmay Shinde
thanks: "TODO - CHANGE THE LINK - Code and data are available at: [https://github.com/Tanmay-Shinde/Week10Reflection](https://github.com/Tanmay-Shinde/Week10Reflection)."
date: today
date-format: long
abstract: "This paper examines how regional and temporal variations influence food-at-home prices across the United States, and the impact of economic factors such as purchase volume, food categories, and the Consumer Price Index (CPI) on these trends. --- The analysis reveals that while food prices have generally increased iver time, certain categories, such as dairy, fresh produce, and meats, tend to exhibit greater volatility. Factors such as purchase volume, food categories, and the CPI have a considerable influence on these price trends. Notably, higher CPI values correlate with increased food prices, and food categories with higher demand or limited supply exhibit more substantial price fluctuations --- . These findings provide actionable insights for policymakers and stakeholders in food economics, emphasizing the impact of region-specific market conditions and consumer purchasing behaviors on food pricing trends."
format: pdf
number-sections: true
toc: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(knitr)
library(ggplot2)
library(dplyr)
library(arrow)

analysis_data <- read_parquet("../data/analysis_data/analysis_data.parquet")

```


# Introduction

Food prices are a critical component of economic and social well-being, directly affecting food security, diet quality, and household expenditures. The Food-at-Home Monthly Area Prices (F-MAP) dataset, developed by the USDA Economic Research Service, offers detailed insights into food pricing trends across the United States. Covering the years 2012 to 2018, the dataset provides monthly price data for 90 food categories across 15 geographic areas, making it a valuable resource for understanding regional and temporal variations in food costs. This paper leverages the F-MAP data to analyze how regional disparities and time-based trends influence food-at-home prices and explores the role of economic factors such as purchase volume, food categories, and the Consumer Price Index (CPI) in shaping these patterns.

The primary focus of this analysis is to estimate how regional differences, food categories, and time affect food prices in the U.S. The estimand is the expected food price for a given food category, time period, and region, conditional on factors such as purchase volume and CPI. By modeling these variations, we aim to uncover the drivers of price changes and predict trends in food costs.

Using a Bayesian hierarchical model, this study analyzes monthly price data from the F-MAP dataset to uncover the drivers of food price variations. The model incorporates random effects to capture regional disparities and fixed effects to analyze the impact of economic factors, such as CPI, purchase volume, and food categories, on price trends. The analysis also highlights categories with greater price volatility and quantifies the influence of these factors on regional and national pricing dynamics. The findings reveal that food prices have generally increased over time, with categories like dairy, fresh produce, and meats experiencing higher price volatility. Economic factors such as purchase volume, food categories, and CPI significantly influence these trends, with higher CPI values strongly correlating with increased prices. Furthermore, food categories with higher demand or limited supply exhibit more substantial price fluctuations, underscoring the importance of understanding market-specific dynamics.

Understanding food pricing trends is essential for addressing issues related to food affordability and access. These insights are particularly valuable for policymakers and stakeholders aiming to reduce regional disparities, promote equitable access to food, and mitigate the effects of inflation on low-income households. By analyzing the drivers of price variations, this study provides a framework for informed decision-making in food policy and economic planning.

The remainder of this paper is structured as follows: @sec-data discusses the data sources, the F-MAP dataset and its variables, and pre-processing methods. @sec-model explains the Bayesian hierarchical model and methodology used for analysis. @sec-result presents the results, followed by a discussion of the key findings and conclusion of the study, as well as the limitations of the data in @sec-discussion. Finally, @sec-appendix --- TODO: COMPLETE WHAT THE APPENDIX INCLUDES ---.


# Data {#sec-data}

## Source and Overview

The Food-at-Home Monthly Area Prices (F-MAP) data product [@USDA_FMAP] is a comprehensive and detailed data product developed by the USDA Economic Research Service (ERS) that provides monthly U.S. food price data for 90 food-at-home (FAH) categories across 15 geographic areas of the United States. The dataset includes two primary price measures for each food group, geographic area, and month: (1) a mean unit value price (dollars per 100 grams) and (2) price indexes derived using advanced index formulas. These measures enable researchers to track food price trends at a granular level and compare them across geographic and temporal dimensions, while accounting for economic factors such as consumer purchasing volume, store characteristics, and inflation metrics like the Consumer Price Index (CPI). By utilizing Circana OmniMarket Core Outlets retail scanner data, the F-MAP captures detailed consumer purchasing data from over 50,000 retail stores annually, including grocery stores, supercenters, and convenience stores.

The F-MAP provides data across the following dimensions:

- Monthly, 2012–18

- 15 geographic areas
  - Nationally
  - 4 Census regions: Midwest, Northeast, South, West
  - 10 metropolitan areas: Atlanta, Boston, Chicago, Dallas, Detroit, Houston, Los Angeles, Miami, New York, and Philadelphia
  
- 90 ERS Food Purchase Groups (EFPGs)
  - 8 groups for grains
  - 23 groups for vegetables
  - 8 groups for fruit
  - 8 groups for dairy and plant-based milk products
  - 14 groups for meat and protein foods
  - 4 groups for prepared meals, sides, and salads
  - 25 groups for other foods

For each of these month, area, and food group combinations, the F-MAP includes the following value variables:

- Purchase_dollars_wtd: Total weighted sales in U.S. dollars (nominal, i.e., not adjusted for inflation)
- Purchase_dollars_unwtd: Total unweighted sales in U.S. dollars (nominal, i.e., not adjusted for inflation)
- Purchase_grams_wtd: Total weighted quantities in grams
- Purchase_grams_unwtd: Total unweighted quantities in grams
- Number_stores: Number of stores in geographic area
- Unit_value_mean_wtd: Weighted mean unit value per 100 grams
- Unit_value_se_wtd: Standard error of weighted mean unit value
- Unit_value_mean_unwtd: Unweighted mean unit value per 100 grams
- Price_index_GEKS: Weighted price index value, constructed using Gini-Eltetö-Köves-Szulc (GEKS) formula

The F-MAP dataset is designed to align closely with the USDA Dietary Guidelines for Americans, facilitating research into food affordability, diet quality, and food security. Unlike other datasets, F-MAP offers monthly frequency data, making it particularly valuable for tracking short-term and seasonal trends. The dataset's hierarchical structure—spanning individual food categories, metropolitan regions, and national aggregates—supports diverse research applications. For example, it can be used to model the effects of policy interventions such as soda taxes or subsidies on dietary behavior and public health outcomes. 

While other datasets such as the Bureau of Labor Statistics (BLS) Consumer Price Index (CPI) and the USDA Purchase to Plate National Average Prices (PP-NAP) provide useful insights, they fall short in capturing the comprehensive geographic and categorical detail offered by F-MAP. For instance, the CPI lacks subnational comparability across regions and provides limited food category detail, while the PP-NAP is focused on prepared foods and lacks the temporal granularity needed for trend analysis. The F-MAP dataset bridges these gaps by offering a more detailed, frequent, and regionally comparable resource.

The data is available to download in .xlsx format on the [USDA Economic Research Service website](https://www.ers.usda.gov/data-products/food-at-home-monthly-area-prices/). Specifically, we use the "Food-at-Home Monthly Area Prices, 2012 to 2018" dataset for our analysis.

## Data Processing and Cleaning

We use the statistical programming language R [@citeR] to clean the data using various helpful packages like, readxl [@cite-readxl], dplyr [@cite-dplyr], tidyr [@cite-tidyr], lubridate [@cite-lubridate], and arrow [@cite-arrow]. Further, libraries like ggplot2 [@cite-gg], knitr [@cite-knitr] were used to analyze the data and create visualizations.

The initial step involved removing unnecessary variables, retaining only those essential for analysis. This included variables such as unit_value_mean_wtd (weighted unit value), purchase_grams_wtd (weighted purchase volume), price_index_GEKS (Consumer Price Index), EFPG (food category), metroregion_name (region), and time. Rows containing missing values in any of the key variables were removed to maintain data integrity. The dependent variable, unitValue, was log-transformed to stabilize variance and linearize relationships, to ensure no assumptions are violations in modelling. The time variable, originally in year-month format, was converted into a continuous variable representing the number of months since January 2012. This allows temporal trends to be modeled effectively as a continuous variable. Categorical variables such as region and category were standardized and converted into factor variables, enabling the model to treat them as categorical inputs. To improve the convergence of the Bayesian model, predictors such as cpi and purchaseVolume were normalized by centering them around zero and scaling them to have a standard deviation of one.


## Measurement
	
The Food-at-Home Monthly Area Prices (F-MAP) dataset is built using high-frequency retail scanner data sourced from approximately 50,000–60,000 retail establishments annually. These include grocery stores, supercenters, club stores, drug stores, and convenience stores. The scanner data capture weekly sales in nominal dollars (not adjusted for inflation) and the quantities of food items sold. Weekly sales data are aggregated into monthly intervals to align with the dataset’s temporal structure. If a sales week spans two months, the sales values and units are proportionately allocated based on the number of days in each month, ensuring temporal consistency.

To standardize the data, outliers in unit values are removed using the interquartile range (IQR) method, which identifies extreme values beyond 1.5 times the IQR from the 25th and 75th percentiles of the price distribution. This step eliminates inaccuracies that might arise from reporting errors or anomalous transactions. Package weights are converted into grams to ensure uniformity, using standard conversion factors (e.g., grams per ounce, fluid ounce, or pound). Prices are then expressed as unit values per 100 grams, providing a consistent measure of price across products of varying sizes.

The categorization of products into 90 detailed food categories is based on the USDA Economic Research Service (ERS) Food Purchase Groups (EFPG) system. This classification system organizes foods by their characteristics, such as ingredients, nutritional content, and convenience level. It aligns closely with the Dietary Guidelines for Americans and enables researchers to aggregate, disaggregate, or customize categories for specific research needs. These EFPG classifications are foundational to understanding price trends within and across food categories.

Retail sales data from certain retailers are reported at a broader Retailer Marketing Area (RMA) level rather than individual store locations. To ensure granularity, these RMA-level sales are disaggregated to individual stores using proportionate weighting methods, based on store-level weights developed specifically for the scanner data. These weights adjust the sales data to reflect the population of stores nationally and regionally, ensuring that the dataset is representative of real-world purchasing behaviors. Both weighted and unweighted unit value estimates are included, enabling diverse analytical approaches.

The dataset also includes price indexes, which measure the cost of a basket of goods over time and across locations. The GEKS multilateral price index, the primary index in the F-MAP, is constructed to compare prices dynamically while accounting for product substitution and turnover. This index is based on the geometric mean of bilateral indexes (Laspeyres, Paasche, Fisher Ideal) and employs a 1-year rolling window to maintain transitivity and minimize chain drift. By capturing the cost of goods relative to a base period (2016–2018 national averages), these price indexes provide a robust measure for temporal and spatial price comparisons, making the dataset suitable for inflation and affordability analyses.

Through this rigorous process, real-world phenomena such as regional price variations, inflationary trends, and food category-specific dynamics are translated into structured data entries. The combination of high-frequency retail data, standardized unit values, and multilateral price indexes ensures that the F-MAP dataset is both comprehensive and precise, supporting its use in economic research and policy-making. A more detailed overview of the measurement process, including the data acquisition, adjustments, and methods for calculating the price index can be found in [Appendix -@sec-data-details].

## Outcome variable

The response variable, unitValue, represents the weighted mean price per 100 grams of a food item within a specific food category, geographic region, and time period. In this analysis, the variable is log-transformed to create unitValue_lg, which helps stabilize variance, improve normality, and facilitate the interpretation of model coefficients in percentage terms. The log transformation allows us to understand the proportional changes in price rather than absolute changes, which is particularly useful for identifying relative price dynamics across categories and regions.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: tbl-outsumm
#| tbl-cap: "Summary Statistics for log of Unit Value"


# Summary statistics for outcome variable
summary_stats_outcome <- analysis_data %>%
  summarise(
    mean = mean(unitValue_lg, na.rm = TRUE),
    median = median(unitValue_lg, na.rm = TRUE),
    sd = sd(unitValue_lg, na.rm = TRUE),
    min = min(unitValue_lg, na.rm = TRUE),
    max = max(unitValue_lg, na.rm = TRUE)
)

kable(summary_stats_outcome)

``` 

From @tbl-outsumm, we can see that the transformed outcome variable, unitValue_lg, has a mean of -0.692 and a median of -0.713, indicating a near-symmetric distribution. The standard deviation of 0.687 reflects moderate variability in prices, while the range, spanning from a minimum of -2.813 to a maximum of 1.191, highlights significant disparities in food costs across categories, regions, and time periods. The log transformation normalizes the data, reducing skewness and ensuring that extreme values in the original price variable do not disproportionately influence the analysis. 

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: fig-hist-out
#| fig-cap: "Distribution of Log-Transformed Food Prices (Unit Value)"

# Histogram for unitValue_lg

ggplot(analysis_data, aes(x = unitValue_lg)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7, color = "black") +
  labs(title = "Distribution of Log Unit Value", x = "Log Unit Value", y = "Frequency") +
  theme_minimal()

``` 

@fig-hist-out illustrates a symmetric, unimodal distribution of unitValue_lg, centered near -0.7, with values ranging from approximately -2.8 to 1.2. This indicates that most food prices cluster around the median value, with fewer extreme high or low prices.

More details and exploratory analysis about the outcome variable can be found in [Appendix -@sec-data-details]

## Predictor variables

### Time

The time variable in the analysis dataset is a continuous variable, representing the number of months since January 2012 when the data was recorded. This variable is important to help us understand temporal trends in the data and fluctuations in the unit value over time. The first month Jan-2012 is represented as 0, Feb-2012 as 1, and so on until Dec-2018 represented as 83.

### Category

It is a categorical variable representing the 90 ERS Food Purchase Groups (EFPGs). The categories include different types of grains, fruits and vegetables, dairy, meat and protein foods, prepared meals, salads, and other foods.

### Region

The region variable represents 15 geographic regions (10 metropolitan areas and 4 Census regions and 1 National category). the region variable will help us analyze the regional and geographical trends and variations in food prices

For each of these time, region, and food group combinations, the F-MAP includes the following value variables:

### Consumer Price Index (CPI)

The Consumer Price Index (CPI) variable in the dataset represents the weighted price index (GEKS index) that measures the cost of a basket of goods over time, standardized relative to a base period (2016–2018). The CPI is unitless, with values below 1 indicating prices lower than the base period average and values above 1 indicating higher prices. The cpi is normalized to improve accuracy in modelling. This variable is critical in understanding inflationary trends and regional price dynamics, as it allows comparisons of relative purchasing power and economic conditions over time and across regions.

Each value recorded under the CPI column represents the consumer price index of one particular food group out of the 90 EFPGs in a particular region for that month.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: tbl-cpisumm
#| tbl-cap: "Summary Statistics for CPI"


# Summary statistics for outcome variable
summary_stats_outcome <- analysis_data %>%
  summarise(
    mean = mean(cpi, na.rm = TRUE),
    median = median(cpi, na.rm = TRUE),
    sd = sd(cpi, na.rm = TRUE),
    min = min(cpi, na.rm = TRUE),
    max = max(cpi, na.rm = TRUE)
)

kable(summary_stats_outcome)

``` 

@tbl-cpisumm illustrates the normalization of the variable with mean as 0 and standard deviation as 1. The minimum and maximum values of -7.04 and 22.79, respectively, highlight the presence of extreme values or outliers. These statistics indicate notable regional or temporal differences in CPI values, reflecting the varying economic conditions or price trends across the observed time period and regions. @fig-hist-cpi also shows a spread of the data from -7 to 22, with most of the values clustered around 0 with a fairly normal distribution.


```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: fig-hist-cpi
#| fig-cap: "Distribution of GEKS Consumer Price Index (CPI)"

# Histogram for cpi values



ggplot(analysis_data, aes(x = cpi)) +
  geom_histogram(bins = 100, fill = "blue", alpha = 0.7, color = "black") +
  labs(title = "Distribution of CPI", x = "CPI", y = "Frequency") +
  theme_minimal()

```

### Purchase Volume










# Model {#sec-model}

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

<!-- Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.   -->

<!-- \begin{align}  -->
<!-- y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\ -->
<!-- \mu_i &= \alpha + \beta_i + \gamma_i\\ -->
<!-- \alpha &\sim \mbox{Normal}(0, 2.5) \\ -->
<!-- \beta &\sim \mbox{Normal}(0, 2.5) \\ -->
<!-- \gamma &\sim \mbox{Normal}(0, 2.5) \\ -->
<!-- \sigma &\sim \mbox{Exponential}(1) -->
<!-- \end{align} -->

<!-- We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`. -->


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results {#sec-result}

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

# library(rstanarm)

#first_model <- readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

# modelsummary::modelsummary(
#   list(
#     "First model" = first_model
#   ),
#   statistic = "mad",
#   fmt = 2
# )
```




# Discussion {#sec-discussion}

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}

# Additional data details {#sec-data-details}

## Measurement
This section describes the methods for constructing the price measures in the F-MAP.

### Data Preparation
The process to prepare the datasets for creating the F-MAP data product are as follows:

1. The retail scanner data report sales on a weekly basis. Weekly sales are grouped into the respective months that the sales occurred. In cases where the week straddles 2 months, sales units and values are allocated proportionately based on the number of days in each month.

2. Unit value outliers are eliminated using the interquartile range (IQR) method. The IQR is the difference between the 25th and 75th percentiles of the price distribution, in this case across all unit values by store and week for each item. A unit value is considered an outlier if the value is below the 25th percentile minus 1.5 multiplied by the IQR or above the 75th percentile plus 1.5 multiplied by the IQR.

3. The weights of each package are converted into grams to calculate unit values on a per 100-gram basis:
   a. Convert from ounces: gram weight = 28.35 x ounces per package
   b. Convert from pounds: gram weight = 28.35 x 16 x pounds per package
   c. Convert from fluid ounces: gram weight = 29.57 x fluid ounces per package
  
4. Individual food items sold in the scanner data (about 600,000 per year) are identified and categorized into 90 food groups, based on the EFPG classification system.

5. Retailer Marketing Area (RMA) sales data are disaggregated to individual stores. In the retail scanner data, most retailers release data by individual store location. However, some retailers only release data by RMA, a grouping of stores in a retailer-defined geographical area. To disaggregate the RMA sales data to individual stores, the RMA sales data are proportioned to individual stores based on the store sales values in the store-level weight files developed for the retail scanner data. For more information about the store weights, see the Using Proprietary Data page.

6. Store-level survey weights are applied to each store. Stores in the retail scanner data are not a representative sample of stores, and store-level weights adjust the sales data to be representative of the population of stores nationally and for each geographic area in the F-MAP. In the F-MAP datasets, unit values are provided as both weighted and unweighted estimates, and the price indexes were calculated using weighted data.

### Unit Values

Sales (in U.S. dollars) and quantity (in grams) are summed over each month, EFPG, and geographic area. Mean unit values in the F-MAP are calculated by dividing the food group sales by the food group quantity and are standardized to the price per 100 grams. This process is completed as follows: (1) calculate the total purchase values in dollars and in grams for each EFPG in a given month and geographic area, weighted by the store weight for that year of data (note, weight is 1 for unweighted estimates); and (2) divide the total (weighted or unweighted) purchase dollars by the total (weighted or unweighted) grams to get the unit price.

The F-MAP also includes standard errors for the weighted unit values. Standard errors are a measure of the precision of survey estimates and can be used to construct confidence intervals for an estimate. Confidence intervals represent a range of values that are likely to include the actual population mean. Standard errors of the weighted unit values are calculated by re-estimating the weighted unit values 200 times, using replicate weights, and then using the general formula for standard errors. These calculations are described in more detail in the Development of the Food-at-Home Monthly Area Prices Data report.

### Price Indices

Price indexes are a unitless measure of the cost of a basket of goods and are used to measure price changes over time. A price index converts many item-level price comparisons into a single value that quantifies the overall price of the basket at a time and location relative to a base period. The base period for the F-MAP is the national average for each EFPG from 2016 through 2018. Index values lower than 1 indicate prices lower than the national average from 2016 through 2018, while index values higher than 1 indicate prices higher than the national average from 2016 through 2018.

The primary F-MAP price index is constructed using a weighted GEKS index formula (named for contributors Gini, Eltetö, Köves, and Szulc). GEKS is a multilateral price index specifically designed to compare prices over time and space. A GEKS index can also be extended for future years without revising the index numbers that have already been published. A GEKS price index is available for all years of the F-MAP (2012–18). A set of supplemental indexes is also available for 2016–18 as a research series, which includes the bilateral Laspeyres, Paasche, Törnqvist, Fisher Ideal indexes and the multilateral Caves-Christensen-Diewert (CCD) index.

Multilateral price indexes are transitive, which means that any month-area pairing (or entity) can be compared directly with another pairing or through a third pairing, and the ratio between any two pairings is independent of the choice of base period. Transitive indexes are advantageous if the mix of goods being measured is dynamic; that is, if the basket of goods changes due to product turnover. Indexes based on scanner data are dynamic because the indexes include all goods sold in stores, which may change in each time period, rather than a sample of goods selected through a survey. Indexes that are transitive also allow spatial comparisons, regardless of the choice of area used for the base.

As additional years of price data become available beyond the base period, the GEKS index can be updated using a rolling window, or the time period over which the index is calculated. In standard multilateral indexes, as new data become available beyond the initial base period, the index numbers for existing entities must be recalculated because the multilateral index compares product prices in an entity with prices in all other entities. A rolling-window GEKS index compares product prices in a new entity with prices of entities within a rolling window. The F-MAP GEKS uses a 1-year rolling window, which allows maintaining published indexes without revising historical numbers.

Bilateral indexes with a fixed base period can become less representative of the cost of food as the indexes move further away from the base, due to the effects of product turnover, as products are discontinued and new products are introduced. Although bilateral price indexes can be updated using chained indexes, which capture product substitution, chained indexes are subject to drifting. Chain drift is a phenomenon in which the price index drifts lower even as item-level prices return to their base levels. Multilateral indexes are fully transitive and free of chain drift. While chain drift is possible in rolling-window multilateral indexes, if a wide window length is chosen, the rolling-window index will be largely free of drift despite not being fully transitive. The 1-year rolling window used in the F-MAP GEKS has been found to be sufficient to remove chain drift caused by high-frequency data and seasonal variation in variety.

The GEKS index builds upon bilateral indexes as elements. The multilateral GEKS index is the geometric mean of all possible Fisher Ideal index month-area pairings. The Fisher Ideal index is, in turn, based on the geometric mean of the Laspeyres and Paasche indexes. Therefore, constructing a GEKS index requires first calculating Laspeyres, Paasche, and Fisher Ideal indexes. We avoid going into deeper details of the above indices as the math gets extremely complicated. For more information about the construction of the F-MAP GEKS, the rolling-window GEKS, and the five supplemental indexes (i.e., Laspeyres, Paasche, Törnqvist, Fisher Ideal, and Caves-Christensen-Diewert (CCD)), you can refer to ERS’s report on the F-MAP methods. [@Sweitzer2024]

## EDA for Outcome Variable

### Regional Trends

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: fig-bxplt-out
#| fig-cap: "Regional Variations in Log-Transformed Food Prices"

filtered_data <- analysis_data %>%
  filter(grepl("Census Region", region, ignore.case = TRUE))

# Boxplot of unitValue_lg by region
ggplot(filtered_data, aes(x = region, y = unitValue_lg)) +
  geom_boxplot(fill = "lightgreen", alpha = 0.7) +
  labs(title = "Log Unit Value by Region", x = "Region", y = "Log Unit Value") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

``` 
@fig-bxplt-out reveals slight regional variations in log unit values. The Northeast and West regions show marginally higher median prices compared to the Midwest and South, reflecting higher food costs often associated with coastal or urban areas. The Midwest exhibits the largest variability, including a notable outlier on the high end, suggesting either an expensive food category or a regional anomaly. Despite these differences, the overall consistency in median prices across regions highlights a broadly stable pricing structure with minor geographic deviations. These trends emphasize the need to investigate the economic and geographic factors contributing to these regional disparities.

### Temporal Trends

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: fig-timetrend
#| fig-cap: "Temporal Variations in Log-Transformed Food Prices"

transformed_data <- analysis_data %>% 
  mutate(time = time/12 + 2012) %>%
  group_by(time) %>%
  summarise(mean_unitValue_lg = mean(unitValue_lg, na.rm = TRUE))

ggplot(transformed_data, aes(x = time, y = mean_unitValue_lg)) +
  geom_line(color = "blue", size = 0.9) +
  labs(title = "Trend Over Time: Log-Transformed Unit Value of Food Prices",
       x = "Time (in Years)",
       y = "Log Unit Value") +
  geom_smooth(method = "loess", color = "red", se = FALSE) +
  theme_minimal()

``` 

@fig-timetrend illustrates the log-transformed unit value of food prices from 2012 to 2018, revealing a general upward trend over time. Initially, from 2012 to 2014, there is only a modest increase in the log-transformed values. However, in 2014, prices increase sharply followed by a period of 3 years characterized by heightened volatility, with pronounced peaks and troughs, and another increase in the prices in 2018. Thus, the overall trajectory for the log-transformed unit value of food prices from 2012 to 2018 remains upwards.

## EDA for Predictor Variables

### CPI

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: fig-bxplt-cpi
#| fig-cap: "Regional Variations in CPI"

filtered_data <- analysis_data %>%
  filter(grepl("Census Region", region, ignore.case = TRUE))

# Boxplot of unitValue_lg by region
ggplot(filtered_data, aes(x = region, y = cpi)) +
  geom_boxplot(fill = "lightgreen", alpha = 0.7) +
  labs(title = "Consumer Price Index (CPI) by Region", x = "Region", y = "CPI") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

@fig-bxplt-cpi reveals noticeable patterns and variations across Census regions. Each region exhibits a centralized cluster of values around the median, with relatively narrow interquartile ranges, indicating that the bulk of CPI values are similar within each region. However, all regions display significant outliers. From the boxplot, we can clearly see that the overall prices in the northeast and midwest regions are comparatively higher than prices in the south and the west census regions, with the west having some of the lowest cpi values out of all the regions.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: fig-timetrend-cpi
#| fig-cap: "Temporal Variations in the Consumer price Index (CPI)"

transformed_data <- analysis_data %>% 
  mutate(time = time/12 + 2012) %>%
  group_by(time) %>%
  summarise(mean_cpi = mean(cpi, na.rm = TRUE))

ggplot(transformed_data, aes(x = time, y = mean_cpi)) +
  geom_line(color = "blue", size = 0.9) +
  labs(title = "Trend Over Time: Consumer Price index",
       x = "Time (in Years)",
       y = "CPI") +
  geom_smooth(method = "loess", color = "red", se = FALSE) +
  theme_minimal()

``` 




# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

# pp_check(first_model) +
#   theme_classic() +
#   theme(legend.position = "bottom")
# 
# posterior_vs_prior(first_model) +
#   theme_minimal() +
#   scale_color_brewer(palette = "Set1") +
#   theme(legend.position = "bottom") +
#   coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

# plot(first_model, "trace")
# 
# plot(first_model, "rhat")
```


Please include an Appendix where you focus on an aspect of surveys, sampling or observational data, related to your paper. This should be an in-depth exploration, akin to the “idealized methodology/survey/pollster methodology” sections of Paper 2. Some aspect of this is likely covered in the Measurement sub-section of your Data section, but this Appendix would be much more detailed, and might include aspects like simulation, links to the literature, explorations and comparisons, among other aspects.


\newpage


# References

